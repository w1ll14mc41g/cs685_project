# Results Directory

This directory contains all output files from the pipeline: generated summaries, evaluation scores, and computed metrics.

## Directory Structure

```
results/
├── dataset-analysis/          # Dataset statistics
├── evaluation/                # LLM-as-Judge evaluation results
│   ├── merged/                # Evaluation of merged summaries
│   ├── offline/               # Evaluation of offline-only summaries
│   ├── old-offline-scores/    # Legacy evaluation results
│   └── web-metrics/           # Web retrieval metrics
├── first-10-merged-summaries/  # Early merged summary experiments
├── merged-summaries/           # Web-augmented summaries
├── offline-summaries-JSON-enforced/  # Offline-only summaries (JSON enforced)
├── offline-summaries-JSON-unenforced/ # Offline-only summaries (legacy)
├── llm_judge_stats.json       # Aggregate LLM-as-Judge statistics
├── cohens_kappa.txt           # Inter-annotator agreement metrics
└── tfidf_aggregate_metrics_*.json  # TF-IDF retrieval metrics
```

## Summary Files

### `merged-summaries/`
Web-augmented summaries combining offline TF-IDF documents with validated web documents.

**File Pattern**: `results-merged-{k}-{timestamp}.json`

**Format**:
```json
[
    {
        "id": "query_0",
        "query": "Should phones be banned in schools?",
        "summary": [
            {
                "claim": "Schools should ban phones",
                "perspectives": [
                    {
                        "text": "Perspective text...",
                        "evidence_docs": [1, "https://example.com/doc"]
                    }
                ]
            },
            {
                "claim": "Schools should allow phones",
                "perspectives": [...]
            }
        ]
    },
    ...
]
```

**Document IDs**: Mixed types (integers for offline docs, URL strings for web docs)

### `offline-summaries-JSON-enforced/`
Offline-only summaries using only TF-IDF retrieved documents.

**File Pattern**: `results-{k}-offline-0-online-tfidf-{timestamp}.json`

**Format**: Same structure as merged summaries, but `evidence_docs` contains only integer IDs.

**Document IDs**: Integer only (from ThePerspective dataset)

### `offline-summaries-JSON-unenforced/`
Legacy offline summaries (pre-JSON enforcement).

**File Pattern**: `tfidf-{k}-offline.json`

## Evaluation Results

### `evaluation/merged/`
LLM-as-Judge evaluation scores for merged summaries.

**File Pattern**: `merged_{k}_llm_judge_scores_{timestamp}.json`

**Format**:
```json
{
    "timestamp": "2025-12-17T10:03:43",
    "model": "gpt-5-nano-2025-08-07",
    "summary_file": "results/merged-summaries/results-merged-5-20251215_082353.json",
    "summary_type": "merged",
    "num_evaluated": 185,
    "num_skipped_errors": 0,
    "results": [
        {
            "id": "query_0",
            "query": "Should phones be banned in schools?",
            "scores": {
                "criterion_1_claim_relevance": 2,
                "criterion_2_perspective_claim_alignment": 2,
                "criterion_3_perspective_distinctness": 2,
                "criterion_4_coverage_of_core_arguments": 2,
                "criterion_5_factual_grounding": 2,
                "total_score": 10
            },
            "error": null,
            "raw_response": "..."
        }
    ]
}
```

**Scoring Criteria** (0-2 points each, total 0-10):
1. Claim relevance
2. Perspective-claim alignment
3. Perspective distinctness
4. Coverage of core arguments
5. Factual grounding

### `evaluation/offline/`
LLM-as-Judge evaluation scores for offline-only summaries.

**File Pattern**: `offline_{k}_llm_judge_scores_{timestamp}.json`

**Format**: Same structure as merged evaluation files.

### `evaluation/web-metrics/`
Web retrieval quality metrics.

**File**: `web_metrics_results.json`

**Metrics**:
- New relevant doc count (per query)
- Relevance rate (relevant count / k)
- Token increase rate (ratio of total tokens to baseline tokens)

**Statistics**: Mean, median, quartiles, and 95% bootstrap confidence intervals for each metric.

## Metrics Files

### `llm_judge_stats.json`
Aggregate statistics across all LLM-as-Judge evaluations.

**Format**:
```json
{
    "merged_5": {"mean": 7.5, "median": 8.0, ...},
    "merged_10": {...},
    "offline_5": {...},
    ...
}
```

### `tfidf_aggregate_metrics_*.json`
TF-IDF retrieval performance metrics.

**Metrics**: Recall@k, Cover@k for different k values.

### `cohens_kappa.txt`
Inter-annotator agreement statistics for human evaluation.

### `dataset-analysis/dataset-metrics.md`
Dataset statistics for ThePerspective dataset.

**Generated by**: `src/utils/compute_dataset_metrics.py`

## File Naming Conventions

### Summary Files
- `results-merged-{k}-{timestamp}.json`: Merged summaries with k offline + k web docs
- `results-{k}-offline-0-online-tfidf-{timestamp}.json`: Offline-only summaries with k docs
- `tfidf-{k}-offline.json`: Legacy offline summaries

### Evaluation Files
- `merged_{k}_llm_judge_scores_{timestamp}.json`: Evaluation of merged summaries
- `offline_{k}_llm_judge_scores_{timestamp}.json`: Evaluation of offline summaries

### Metrics Files
- `*_metrics_{timestamp}.json`: Timestamped metrics files
- `llm_judge_stats.json`: Aggregate statistics (no timestamp)

## Interpreting Results

### Summary Quality
- **Total Score**: 0-10 points (higher is better)
- **Individual Criteria**: 0-2 points each
- **Error Field**: `null` if successful, error message if evaluation failed

### Comparison
Compare merged vs. offline summaries:
- Higher scores indicate better quality
- Check `num_skipped_errors` to see how many summaries had errors
- Review individual criterion scores to identify strengths/weaknesses

### Web Metrics
- **Relevance Rate**: Percentage of web docs that are relevant (higher is better)
- **Token Increase**: How much additional content web docs add (indicates information gain)

## Related Modules

- **Summarization** (`src/summarization/`): Generates summary files
- **Evaluation** (`src/evaluation/`): Generates evaluation and metrics files
- **Utils** (`src/utils/`): Generates dataset analysis files

