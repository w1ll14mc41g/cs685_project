# Data Directory

This directory contains input datasets, intermediate processing files, and evaluation sets used throughout the pipeline.

## Directory Structure

```
data/
├── theperspective/        # ThePerspective dataset (PerSphere subset)
├── perspectrumx/         # PerspectrumX dataset (optional)
├── web/                  # Raw web retrieval results
├── valid-web/            # Relevance-validated web documents
├── merged-corpus/        # Merged offline + web documents
├── valid-queries/        # Valid queries for evaluation
└── human-eval/           # Human evaluation context files
```

## Input Datasets

### `theperspective/`
ThePerspective dataset subset of PerSphere.

**Files**:
- `data.jsonl`: Query, claims, and perspectives (one JSON object per line)
- `doc_new.jsonl`: Evidence documents (one JSON object per line)

**Format** (`data.jsonl`):
```json
{
    "id": "Entertainment_0",
    "response1": ["perspective 1", "perspective 2", ...],
    "response2": ["perspective 1", "perspective 2", ...],
    "favor_ids": [205, 364],
    "against_ids": [1138, 858],
    "t1": "Claim 1 text",
    "t2": "Claim 2 text",
    "title": "Topic title"
}
```

**Format** (`doc_new.jsonl`):
```json
{
    "id": 0,
    "content": "Document text..."
}
```

**Statistics**:
- 185 controversial queries
- 4,107 evidence documents
- Average 6 perspectives per query
- Two opposing claims per query

**Usage**: Loaded by `src/utils/io.py` functions.

### `perspectrumx/`
PerspectrumX dataset (optional, not fully implemented).

**Files**:
- `evidence_pool.json`
- `perspective_pool_v1.0.json`
- `perspectrumx.json`

## Intermediate Processing Files

### `web/`
Raw web retrieval results from Tavily API.

**File Pattern**: `web-{k}.json` (k = 5, 10, 20)

**Format**:
```json
[
    {
        "id": "query_0",
        "query": "Should phones be banned in schools?",
        "web_docs": {
            "num_docs": 5,
            "api_k": 5,
            "results": [
                {
                    "id": 0,
                    "content": "Document content...",
                    "url": "https://example.com",
                    "source_type": "web",
                    "title": "Document Title",
                    "domain": "example.com"
                },
                ...
            ]
        }
    },
    ...
]
```

**Generated by**: `src/retrieval/web_retrieval.py` (via `run_pipeline.py`)

### `valid-web/`
Web documents with relevance labels (R/NR) from LLM-as-Judge classification.

**File Pattern**: `valid-web-{k}.json` (k = 5, 10, 20)

**Format**: Same structure as `web/` files, but each document in `results` includes a `relevance` field:
```json
{
    "id": 0,
    "content": "Document content...",
    "url": "https://example.com",
    "relevance": "R"  // or "NR"
}
```

**Generated by**: `src/validation/run_relevance_check.py`

**Usage**: Used by `src/summarization/merge.py` to filter relevant documents.

### `merged-corpus/`
Merged corpus combining offline TF-IDF documents with validated web documents.

**File Pattern**: `merged-{k}.json` (k = 5, 10, 20)

**Format**:
```json
[
    {
        "id": "query_0",
        "query": "Should phones be banned in schools?",
        "merged": [
            {
                "id": 1,  // Integer ID from offline corpus
                "content": "Document content...",
                "score": 0.87
            },
            {
                "id": "https://example.com/doc",  // URL string from web
                "content": "Web document content..."
            },
            ...
        ]
    },
    ...
]
```

**Document ID Types**:
- Integers: Offline documents from ThePerspective dataset
- URL strings: Web documents (starting with "https://")

**Generated by**: `src/summarization/merge.py` (via `run_pipeline.py`)

**Usage**: Used by `src/summarization/llm_summary_merged.py` for merged summarization.

## Evaluation Sets

### `valid-queries/`
Queries that have valid (non-error) summaries in both offline and merged files.

**Files**:
- `valid-k-{k}-queries-{timestamp}.json`: Auto-generated valid queries
- `summary_eval_{k}.json`: Manually curated evaluation sets
- `relevance_eval_{k}.json`: Relevance evaluation sets

**Format**:
```json
[
    {
        "id_offline": "query_0",
        "id_merged": "query_0",
        "query": "Should phones be banned in schools?"
    },
    ...
]
```

**Generated by**: `src/validation/find_valid_queries.py`

**Usage**: 
- Used by `src/evaluation/run_llm_judge_batch.py` to filter valid summaries
- Used by `src/utils/parse_human_judge_context.py` to generate evaluation context

### `human-eval/`
HTML context files for human evaluation of summaries.

**File Pattern**: `llm_as_judge_context-{timestamp}.html`

**Generated by**: `src/utils/parse_human_judge_context.py`

**Features**:
- Interactive HTML interface
- Query navigation dropdown
- Side-by-side comparison of gold reference, offline summary, and merged summary
- Web document display for merged summaries
- Toggle between summary types

**Input**: `data/valid-queries/summary_eval_{k}.json`

## Data Flow

```
1. Input Datasets
   theperspective/ → Loaded by src/utils/io.py

2. Web Retrieval
   → data/web/web-{k}.json (via src/retrieval/web_retrieval.py)

3. Relevance Validation
   data/web/web-{k}.json → data/valid-web/valid-web-{k}.json
   (via src/validation/run_relevance_check.py)

4. Corpus Merging
   Offline docs + data/valid-web/valid-web-{k}.json
   → data/merged-corpus/merged-{k}.json
   (via src/summarization/merge.py)

5. Summary Generation
   data/merged-corpus/merged-{k}.json → results/merged-summaries/
   (via src/summarization/llm_summary_merged.py)

6. Valid Query Finding
   results/merged-summaries/ + results/offline-summaries-JSON-enforced/
   → data/valid-queries/valid-k-{k}-queries-{timestamp}.json
   (via src/validation/find_valid_queries.py)

7. Human Evaluation Context
   data/valid-queries/summary_eval_{k}.json
   → data/human-eval/llm_as_judge_context-{timestamp}.html
   (via src/utils/parse_human_judge_context.py)
```

## File Size Guidelines

- **ThePerspective dataset**: ~4,107 documents, ~185 queries
- **Web retrieval**: Varies by k (5, 10, 20 documents per query)
- **Merged corpus**: Offline docs + relevant web docs (typically 5-20 per query)
- **Valid queries**: Subset of queries with valid summaries (typically 20-30 for evaluation)

## Related Modules

- **Utils** (`src/utils/`): Loads input datasets
- **Retrieval** (`src/retrieval/`): Generates web retrieval files
- **Validation** (`src/validation/`): Generates valid-web and valid-queries files
- **Summarization** (`src/summarization/`): Generates merged-corpus files
- **Evaluation** (`src/evaluation/`): Uses valid-queries for evaluation

